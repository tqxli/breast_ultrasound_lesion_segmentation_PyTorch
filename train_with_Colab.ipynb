{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_with_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMdxEqZYaQvbGog1ncfOgDN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W9Ah-uuPjuI"
      },
      "source": [
        "### Preparations\n",
        "First clone the repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAjKMHg-vYjE",
        "outputId": "0e385296-5e01-4c37-8728-d6d125096fbd"
      },
      "source": [
        "!git clone https://github.com/tqxli/breast_ultrasound_lesion_segmentation_PyTorch.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'breast_ultrasound_lesion_segmentation_PyTorch'...\n",
            "remote: Enumerating objects: 180, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 180 (delta 86), reused 116 (delta 45), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (180/180), 60.53 KiB | 8.65 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHN1bCF3FpZT"
      },
      "source": [
        "Also mount your own Google Drive (so that your experiment results can be saved more easily). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLNg7zdZFqXL",
        "outputId": "24d90467-8e0b-416f-8e6f-177f7626f839"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SpIJONLPx26"
      },
      "source": [
        "Change current directory to the folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvLlKhzTvbCt",
        "outputId": "ff0714b9-5952-406a-dffb-ecf7c73c1832"
      },
      "source": [
        "%cd /content/breast_ultrasound_lesion_segmentation_PyTorch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/breast_ultrasound_lesion_segmentation_PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCbbQTBsP7We"
      },
      "source": [
        "### Dataset\n",
        "Run the script below to download the needed BUSI dataset for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Hun_Idvfml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f01824-042d-48cb-f966-6c63233cc8b2"
      },
      "source": [
        "!python BUSI/BUSI_prepare_for_training.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1_JTLKi8bxfv-DeCvJWiZrsdxi2eCRF9r into ./BUSI/BUSI_train.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrFPgZGOQ7N2"
      },
      "source": [
        "### Ensure all dependencies are installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG8aoLyU0SDU"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SU8f_dRQGVr"
      },
      "source": [
        "### Prepare for Tensorboard visualization:\n",
        "Create a folder (\"exp_results\") for storing your experiment results in the drive. \n",
        "\n",
        "Folder 'log' should contain all tensorboard logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwu5iRxRnXYl"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('../drive/MyDrive/exp_results'):\n",
        "    os.mkdir('../drive/MyDrive/exp_results')\n",
        "if not os.path.isdir('../drive/MyDrive/exp_results/log'):\n",
        "    os.mkdir('../drive/MyDrive/exp_results/log')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctlmZjqYQjW0"
      },
      "source": [
        "Load the embedded tensorboard extension and specify the logdir. The tensorboard interface should then appear below.\n",
        "\n",
        "Select 'Settings/reload' to be true if you wish the interface to refresh automatically itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goCbSt8BowYZ"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ../drive/MyDrive/exp_results/log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeaU4U1IQ7Av"
      },
      "source": [
        "### Start training!\n",
        "Check before run:\n",
        "* Parent of Tensorboard's logdir needs to match with the 'save_dir' in the json file. \n",
        "\n",
        "  For this demonstration, save_dir = '../drive/MyDrive/exp_results'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPsf61uDP5TM"
      },
      "source": [
        "Remember to select the wanted config file for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbfBd60ns7tn"
      },
      "source": [
        "!python train.py --config options/ResUNet.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8qm086oP0Pu"
      },
      "source": [
        "You can also resume training from a previous checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr7dwvOBJW4V"
      },
      "source": [
        "!python train.py --config options/Attn_UNet.json  --resume ../drive/MyDrive/exp_results/models/ResUNet/0420_024631/checkpoint-epoch50.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P73fa-V9VbcO"
      },
      "source": [
        "### Save your results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XZwws4gRTBi"
      },
      "source": [
        "If you follow the instructions above, all the experiment results (checkpoints, training logs, tensorboard logs, configs) should be saved in your own Google Drive. \n",
        "\n",
        "**Notice**: Colab is terrible at fetching (downloading) **large** files such as model weights. If needed (not recommended!), follow the below method to download the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx5FynMYY--y"
      },
      "source": [
        "!zip -r ResUNet.zip exp_results/models/ResUNet/0420_024631/checkpoint-epoch50.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TU66AMy_3SA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0446ebd2-0e3b-44c7-face-5ea67181efb0"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('./ResUNet.zip')\n",
        "except ImportError:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_af2cb279-4987-489f-b0cf-a4674c0ccdc5\", \"ResUNet.zip\", 570292181)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}